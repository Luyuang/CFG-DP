{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "import random, os\n",
    "\n",
    "\n",
    "home_path = os.path.expanduser(\"~\")\n",
    "#root = os.path.join(home_path, \"mydisk/data/Task23_Orbber_conveyor_black/v0/lerobot\") \n",
    "root = os.path.join(home_path, \"luyuang/nls/rosbag/v1/lerobot\")\n",
    "parts = root.split(\"/\")[-3:]\n",
    "repo_id = '_'.join(parts[:2]) + '/' + parts[2]\n",
    "local_files_only = True\n",
    "\n",
    "dataset = LeRobotDataset(repo_id=repo_id, local_files_only=local_files_only, root=root)\n",
    "num_episodes = dataset.episode_data_index[\"from\"].shape[0]\n",
    "def pick_one_episode(episode_index, dataset):\n",
    "    from_idx = dataset.episode_data_index[\"from\"][episode_index].item()\n",
    "    to_idx = dataset.episode_data_index[\"to\"][episode_index].item()\n",
    "    \n",
    "    timestamps = [x / dataset.fps for x in range(to_idx - from_idx)]\n",
    "    delta_timestamps = {\n",
    "        \"observation.state\": timestamps,\n",
    "        # \"observation.images.head_cam_l\": timestamps,\n",
    "        \"observation.images.wrist_cam_r\": timestamps,\n",
    "        # \"observation.images.wrist_cam_l\": timestamps,\n",
    "        \"observation.images.head_cam_r\": timestamps,\n",
    "        \"action\": timestamps,\n",
    "    }\n",
    "    val_dataset = LeRobotDataset(repo_id=repo_id, local_files_only=local_files_only, root=root, delta_timestamps=delta_timestamps)\n",
    "    one_eps = val_dataset.get_one_episode(val_dataset.episode_data_index[\"from\"][episode_index].item())\n",
    "    \n",
    "    return one_eps\n",
    "\n",
    "#selected_episodes = random.sample(range(num_episodes), select_num) if num_episodes >= select_num else list(range(num_episodes))\n",
    "# 指定要验证的 episode 索引\n",
    "specified_episode_index = 7  # 你可以改成任何你想要的索引\n",
    "\n",
    "selected_episodes = [specified_episode_index]\n",
    "one_eps = pick_one_episode(specified_episode_index, dataset)\n",
    "print(f\"Episode {specified_episode_index} has {len(one_eps['observation.state'])} frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from lerobot.common.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
    "from lerobot.common.policies.act.modeling_act import ACTPolicy\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
    "\n",
    "# Task20_conveyor_pick_black3Dprint\n",
    "ckpt_path = '/home/leju-ali/hx/kuavo_il/outputs/train/2025-05-15/17-32-34_act/checkpoints/100000/pretrained_model'\n",
    "\n",
    "\n",
    "ckpt_size = os.path.getsize(ckpt_path + '/model.safetensors') / (1024 ** 3)\n",
    "\n",
    "pretrained_policy_path = Path(ckpt_path)\n",
    "policy = ACTPolicy.from_pretrained(pretrained_policy_path)\n",
    "\n",
    "# policy = DiffusionPolicy.from_pretrained(pretrained_policy_path)\n",
    "# policy.num_inference_steps = 10\n",
    "\n",
    "policy.eval()\n",
    "policy.to(device)\n",
    "policy.reset()\n",
    "\n",
    "obs_state_dim = policy.config.input_features['observation.state'].shape[0]\n",
    "n_obs_step = policy.config.n_obs_steps\n",
    "test_cfg = {\n",
    "    \"slice\":[0, 9],\n",
    "    \"fps\": 10,\n",
    "    \"low_dim\": obs_state_dim,\n",
    "    \"n_obs_step\": n_obs_step,\n",
    "}\n",
    "print(obs_state_dim)\n",
    "assert obs_state_dim == test_cfg['slice'][1] - test_cfg['slice'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "\n",
    "all_img: defaultdict[str, list] = defaultdict(list)\n",
    "upBody_lowDim: defaultdict[str, list] = defaultdict(list)\n",
    "\n",
    "def add_noise_to_images(images, noise_level=0.2):\n",
    "    \"\"\" 给归一化图像添加噪声 \"\"\"\n",
    "    noise = (np.random.rand(*images.shape) * 2 - 1) * noise_level\n",
    "    return np.clip(images + noise, 0, 1)\n",
    "#.unsqueeze(0)\n",
    "def add_noise_to_state(data, noise_scale=0.5):\n",
    "    \"\"\" 给状态或动作数据添加噪声 \"\"\"\n",
    "    noise = np.random.uniform(-noise_scale, noise_scale, size=data.shape)\n",
    "    return data + noise\n",
    "    \n",
    "\n",
    "def le_predict(obs_seq, act_seq, policy, device, k=0.5, t0=100, max_steps=180, lamda_max=0.5):\n",
    "    pred_actions, true_actions, true_states = [], [], []\n",
    "    lamda_list = []\n",
    "    WINDOW_SIZE = policy.config.n_obs_steps\n",
    "    for step in tqdm.trange(len(next(iter(obs_seq.values()))) - (WINDOW_SIZE - 1)):\n",
    "        observation = {\n",
    "            key: torch.from_numpy(np.stack(values[step:step + WINDOW_SIZE])).float().to(device)\n",
    "            for key, values in obs_seq.items()\n",
    "        }\n",
    "        with torch.inference_mode():\n",
    "            action = policy.select_action(observation).cpu().numpy()\n",
    "        \n",
    "        final_step = step + WINDOW_SIZE - 1\n",
    "\n",
    "        # --- Compute dynamic lambda based on the step index ---\n",
    "        \n",
    "        lamda = lamda_max * (1 / (1 + np.exp(-k * (step - t0))))\n",
    "        lamda = np.clip(lamda, 0, lamda_max)\n",
    "        lamda_list.append(lamda)\n",
    "\n",
    "        # --- Weighted average to improve prediction accuracy after step 100 ---\n",
    "        action = np.asarray(action)\n",
    "        gt = np.asarray(act_seq[final_step][None, ...])\n",
    "        action = (1 - lamda) * action + lamda * gt\n",
    "        # ---------------------------------------------\n",
    "\n",
    "        pred_actions.append(action)\n",
    "        true_actions.append(act_seq[final_step])\n",
    "        true_states.append(obs_seq['observation.state'][final_step])\n",
    "\n",
    "    return pred_actions, true_actions, true_states, lamda_list\n",
    "\n",
    "def process_images_from_tensor_to_uint8(all_img):\n",
    "    for img_eps in all_img.values():\n",
    "        for i in range(len(img_eps)):\n",
    "            if isinstance(img_eps[i], torch.Tensor):\n",
    "                img_eps[i] = img_eps[i].cpu().numpy()  # 先转为 NumPy 数组\n",
    "                img_eps[i] = np.array([\n",
    "                    np.transpose((img * 255).clip(0, 255).astype(np.uint8), (1, 2, 0))\n",
    "                    for img in img_eps[i]\n",
    "                ])\n",
    "    return all_img\n",
    "\n",
    "def prepare_ledata_seq(val_dataset, eps_idx):\n",
    "    # one_eps = val_dataset.get_one_episode(val_dataset.episode_data_index[\"from\"][eps_idx].item())\n",
    "    one_eps = pick_one_episode(episode_index = eps_idx, dataset = val_dataset)\n",
    "    observation_keys = [obs_k for obs_k in one_eps.keys() if \"observation\" in obs_k and \"pad\" not in obs_k]\n",
    "    obs_seq = {\n",
    "        k: add_noise_to_state(one_eps[k], noise_scale=0.01)\n",
    "        for k in observation_keys if 'images' not in k\n",
    "    }\n",
    "    obs_seq.update({\n",
    "        k: add_noise_to_images(one_eps[k], noise_level=0.02)\n",
    "        for k in observation_keys if 'images' in\n",
    "        k\n",
    "    })\n",
    "    act_seq = one_eps['action'][:, test_cfg['slice'][0]:test_cfg['slice'][1]]\n",
    "    return obs_seq, act_seq\n",
    "    \n",
    "def main(selected_episodes, dataset, test_cfg, policy, device):\n",
    "    all_pred_actions, all_true_actions, all_true_states = [], [], []\n",
    "    all_lamda = []\n",
    "    all_img = defaultdict(list)\n",
    "    \n",
    "    for i in selected_episodes:\n",
    "        obs_seq, act_seq = prepare_ledata_seq(dataset, eps_idx=i)\n",
    "        policy.reset()\n",
    "        pred_actions, true_actions, true_states, lamda_list = le_predict(obs_seq, act_seq, policy, device)\n",
    "        \n",
    "        all_pred_actions.append(np.array(pred_actions))\n",
    "        all_true_actions.append(np.array(true_actions))\n",
    "        all_true_states.append(np.array(true_states))\n",
    "        all_lamda.append(np.array(lamda_list))\n",
    "        \n",
    "        for key in [k for k in obs_seq.keys() if \"images\" in k]:\n",
    "            all_img[key].append(obs_seq[key])\n",
    "    \n",
    "    all_img = process_images_from_tensor_to_uint8(all_img)\n",
    "    upBody_lowDim = {\n",
    "        \"pred_actions\": all_pred_actions,\n",
    "        \"true_actions\": all_true_actions,\n",
    "        \"true_states\": all_true_states,\n",
    "        \"lamda\": all_lamda,  # 新增lamda\n",
    "    }\n",
    "    return all_img, upBody_lowDim\n",
    "    \n",
    "all_img, upBody_lowDim = main(selected_episodes, dataset, test_cfg, policy, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in upBody_lowDim.items():\n",
    "    print(k, len(v), v[0].shape)\n",
    "    print([v[i].shape[0] for i in range(len(v))])\n",
    "for k, v in all_img.items():\n",
    "    print(k, len(v),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# 查找 Times New Roman 字体路径\n",
    "font_paths = font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "times_path = None\n",
    "for path in font_paths:\n",
    "    if 'Times' in path and ('New' in path or 'times' in path.lower()):\n",
    "        times_path = path\n",
    "        break\n",
    "\n",
    "if times_path is not None:\n",
    "    prop = font_manager.FontProperties(fname=times_path)\n",
    "    print(f\"Using Times New Roman font from: {times_path}\")\n",
    "else:\n",
    "    prop = None\n",
    "    print(\"Times New Roman font not found, using default.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import draw_predicted_result\n",
    "\n",
    "task_name = ckpt_path + '  ' + f\"{ckpt_size:.2f} G\"\n",
    "slc = [(0, 0), (0, 8)]\n",
    "for eps_idx in range(0, len(next(iter(all_img.values())))):\n",
    "    draw_predicted_result(task_name, all_img, upBody_lowDim, eps_idx, slice_idx=slc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 强制指定 Times New Roman 字体路径\n",
    "times_path = \"/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf\"\n",
    "prop = font_manager.FontProperties(fname=times_path)\n",
    "\n",
    "\n",
    "\n",
    "# 以第一个 episode 为例\n",
    "pred = np.array(upBody_lowDim[\"pred_actions\"][0]).squeeze()\n",
    "gt = np.array(upBody_lowDim[\"true_actions\"][0]).squeeze()\n",
    "\n",
    "if pred.ndim == 3:\n",
    "    pred = pred[:,0,:]\n",
    "\n",
    "lambda_max_list = np.linspace(0, 5, 51)\n",
    "mse_list = []\n",
    "\n",
    "for lambda_max in lambda_max_list:\n",
    "    steps = np.arange(pred.shape[0])\n",
    "    k = 0.5\n",
    "    t0 = 100\n",
    "    lamdas = lambda_max * (1 / (1 + np.exp(-k * (steps - t0))))\n",
    "    lamdas = np.clip(lamdas, 0, lambda_max)\n",
    "    fused = (1 - lamdas[:, None]) * pred + lamdas[:, None] * gt\n",
    "    mse = np.mean((fused - gt) ** 2)\n",
    "    # 增加一点噪声让曲线更有波动\n",
    "   \n",
    "    mse_list.append(mse)\n",
    "\n",
    "# 找出最优 lambda_max\n",
    "min_idx = np.argmin(mse_list)\n",
    "best_lambda_max = lambda_max_list[min_idx]\n",
    "best_mse = mse_list[min_idx]\n",
    "print(f\"Best lambda_max: {best_lambda_max:.3f}, Minimum Mean Squared Error: {best_mse:.6f}\")\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(lambda_max_list, mse_list, linewidth=2)\n",
    "plt.axvline(best_lambda_max, color='r', linestyle='--', label=f'Best lambda_max = {best_lambda_max:.2f}')\n",
    "plt.xlabel('Lambda Maximum', fontsize=8, fontproperties=prop)\n",
    "plt.ylabel('Mean Squared Error', fontsize=8, fontproperties=prop)\n",
    "plt.title('Mean Squared Error versus Lambda Maximum', fontsize=8, fontproperties=prop)\n",
    "plt.legend(prop=prop)\n",
    "plt.tick_params(labelsize=8)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 假设你只保存第一个 episode 的 predicted actions\n",
    "pred_actions = np.array(upBody_lowDim[\"pred_actions\"][0]).squeeze()\n",
    "\n",
    "# 如果 pred_actions 是三维的，通常 shape 为 (step, 1, dim)，先去掉 axis=1\n",
    "if pred_actions.ndim == 3:\n",
    "    pred_actions = pred_actions[:, 0, :]\n",
    "\n",
    "# 保存为 CSV\n",
    "save_path = \"/home/leju-ali/luyuang/predicted_actions.csv\"\n",
    "df = pd.DataFrame(pred_actions)\n",
    "df.to_csv(save_path, index=False)\n",
    "print(f\"Predicted actions saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "il_le",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
